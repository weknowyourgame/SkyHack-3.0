{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a021680a-9f28-4985-8e5e-4029db816b8e",
   "metadata": {},
   "source": [
    "## Flight Difficulty Score Development\n",
    "## Objective\n",
    "### Build a daily-level Flight Difficulty Score for ORD departures, ranking flights and classifying them as Difficult, Medium, or Easy.\n",
    "\n",
    "## Prerequisites\n",
    "- Python 3.x+, libraries: `pandas`, `numpy`, `statsmodels`\n",
    "- Install: `pip install -r requirements.txt`\n",
    "- Input: `Flight Level Data.csv`, `Bag Level Data.csv`, `PNR Flight Level Data.csv`, `PNR Remark Level Data.csv`, `eda_metrics.csv` (optional)\n",
    "\n",
    "### Approach\n",
    "- Use OLS regression to predict delay (difficulty proxy), inspired by paperâ€™s ML for delay prediction.\n",
    "- Features: ground time constraint, bag ratio, load factor, SSR per pax, departure hour, haul, fleet type.\n",
    "- Rank flights daily by score; classify into tertiles (Difficult: top 33%, Medium: 33-67%, Easy: bottom 33%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "081db0d2-6de3-4c2b-a34d-b1a467bcf26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2052b3a-fccc-427e-8208-3365fcf6e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.FileHandler('difficulty_score.log'), logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a1e758c-16bb-46ca-b4f9-09849f291ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 17:13:07,781 - INFO - Loaded data\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    flight_df = pd.read_csv('Flight_Level_Data.csv')\n",
    "    bag_df = pd.read_csv('Bag_Level_Data.csv')\n",
    "    pnr_df = pd.read_csv('PNR_Flight_Level_Data.csv')\n",
    "    remark_df = pd.read_csv('PNR_Remark_Level_Data.csv')\n",
    "    logger.info(\"Loaded data\")\n",
    "except FileNotFoundError:\n",
    "    logger.error(\"Data not found\")\n",
    "\n",
    "flight_df = flight_df[flight_df['scheduled_departure_station_code'] == 'ORD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c63b50ee-520b-473c-8967-2ddfa0f6c918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique fleet types: ['ERJ-175' 'B767-300' 'B737-800' 'CRJ-200' 'A319-100' 'B757-300' 'B787-10'\n",
      " 'B737-MAX8' 'B737-MAX9' 'B737-700' 'CRJ-550' 'B737-900' 'A321-2NX'\n",
      " 'A320-200' 'B787-8' 'B757-200' 'B777-2HD' 'ERJ-170' 'B787-9' 'B777-300'\n",
      " 'B767-400']\n",
      "\n",
      "Fleet dummy columns created: ['fleet_type', 'fleet_A319-100', 'fleet_A320-200', 'fleet_A321-2NX', 'fleet_B737-700', 'fleet_B737-800', 'fleet_B737-900', 'fleet_B737-MAX8', 'fleet_B737-MAX9', 'fleet_B757-200', 'fleet_B757-300', 'fleet_B767-300', 'fleet_B767-400', 'fleet_B777-2HD', 'fleet_B777-300', 'fleet_B787-10', 'fleet_B787-8', 'fleet_B787-9', 'fleet_CRJ-200', 'fleet_CRJ-550', 'fleet_ERJ-170', 'fleet_ERJ-175']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique fleet types:\", full_df['fleet_type'].unique())\n",
    "print(\"\\nFleet dummy columns created:\", [col for col in full_df.columns if col.startswith('fleet_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdb91b8d-54b0-4f8e-acdb-fb58443f0894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of features:\n",
      "ground_tight         int64\n",
      "bag_ratio          float64\n",
      "load_factor        float64\n",
      "ssr_per_pax        float64\n",
      "dep_weight         float64\n",
      "haul_hours         float64\n",
      "fleet_A319-100        bool\n",
      "fleet_A320-200        bool\n",
      "fleet_A321-2NX        bool\n",
      "fleet_B737-700        bool\n",
      "fleet_B737-800        bool\n",
      "fleet_B737-900        bool\n",
      "fleet_B737-MAX8       bool\n",
      "fleet_B737-MAX9       bool\n",
      "fleet_B757-200        bool\n",
      "fleet_B757-300        bool\n",
      "fleet_B767-300        bool\n",
      "fleet_B767-400        bool\n",
      "fleet_B777-2HD        bool\n",
      "fleet_B777-300        bool\n",
      "fleet_B787-10         bool\n",
      "fleet_B787-8          bool\n",
      "fleet_B787-9          bool\n",
      "fleet_CRJ-200         bool\n",
      "fleet_CRJ-550         bool\n",
      "fleet_ERJ-170         bool\n",
      "fleet_ERJ-175         bool\n",
      "dtype: object\n",
      "\n",
      "Any non-numeric values:\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     72\u001b[39m X = X[valid_idx]\n\u001b[32m     73\u001b[39m y = y[valid_idx]\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m model = \u001b[43msm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m.fit()\n\u001b[32m     76\u001b[39m full_df.loc[valid_idx, \u001b[33m'\u001b[39m\u001b[33mdifficulty_score\u001b[39m\u001b[33m'\u001b[39m] = np.abs(model.predict(X))\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(model.summary())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:921\u001b[39m, in \u001b[36mOLS.__init__\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    918\u001b[39m     msg = (\u001b[33m\"\u001b[39m\u001b[33mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    919\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mAn exception will be raised in the next version.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    920\u001b[39m     warnings.warn(msg, ValueWarning)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._init_keys:\n\u001b[32m    924\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_keys.remove(\u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:746\u001b[39m, in \u001b[36mWLS.__init__\u001b[39m\u001b[34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    745\u001b[39m     weights = weights.squeeze()\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    748\u001b[39m nobs = \u001b[38;5;28mself\u001b[39m.exog.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    749\u001b[39m weights = \u001b[38;5;28mself\u001b[39m.weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/statsmodels/regression/linear_model.py:200\u001b[39m, in \u001b[36mRegressionModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28mself\u001b[39m.pinv_wexog: Float64Array | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28mself\u001b[39m._data_attr.extend([\u001b[33m'\u001b[39m\u001b[33mpinv_wexog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwendog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwexog\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/statsmodels/base/model.py:270\u001b[39m, in \u001b[36mLikelihoodModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28mself\u001b[39m.initialize()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/statsmodels/base/model.py:95\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, endog, exog, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m missing = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mmissing\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     94\u001b[39m hasconst = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mhasconst\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28mself\u001b[39m.data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                              \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m.k_constant = \u001b[38;5;28mself\u001b[39m.data.k_constant\n\u001b[32m     98\u001b[39m \u001b[38;5;28mself\u001b[39m.exog = \u001b[38;5;28mself\u001b[39m.data.exog\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/statsmodels/base/model.py:135\u001b[39m, in \u001b[36mModel._handle_data\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     data = \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/statsmodels/base/data.py:675\u001b[39m, in \u001b[36mhandle_data\u001b[39m\u001b[34m(endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m    672\u001b[39m     exog = np.asarray(exog)\n\u001b[32m    674\u001b[39m klass = handle_data_class_factory(endog, exog)\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m             \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/statsmodels/base/data.py:84\u001b[39m, in \u001b[36mModelData.__init__\u001b[39m\u001b[34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m.orig_endog = endog\n\u001b[32m     83\u001b[39m     \u001b[38;5;28mself\u001b[39m.orig_exog = exog\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28mself\u001b[39m.endog, \u001b[38;5;28mself\u001b[39m.exog = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_endog_exog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m.const_idx = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;28mself\u001b[39m.k_constant = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/statsmodels/base/data.py:509\u001b[39m, in \u001b[36mPandasData._convert_endog_exog\u001b[39m\u001b[34m(self, endog, exog)\u001b[39m\n\u001b[32m    507\u001b[39m exog = exog \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np.asarray(exog)\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endog.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exog.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPandas data cast to numpy dtype of object. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33mCheck input data with np.asarray(data).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._convert_endog_exog(endog, exog)\n",
      "\u001b[31mValueError\u001b[39m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "# Convert datetime columns to proper datetime format\n",
    "flight_df['scheduled_departure_datetime_local'] = pd.to_datetime(flight_df['scheduled_departure_datetime_local'])\n",
    "flight_df['scheduled_arrival_datetime_local'] = pd.to_datetime(flight_df['scheduled_arrival_datetime_local'])\n",
    "flight_df['actual_departure_datetime_local'] = pd.to_datetime(flight_df['actual_departure_datetime_local'])\n",
    "\n",
    "# Ground time constraint\n",
    "flight_df['ground_tight'] = (flight_df['scheduled_ground_time_minutes'] - flight_df['minimum_turn_minutes'] <= 5).astype(int)\n",
    "\n",
    "# Bag ratio (fixed)\n",
    "bag_grouped = bag_df.groupby(['company_id', 'flight_number', 'scheduled_departure_date_local'])['bag_type'].value_counts().unstack(fill_value=0)\n",
    "bag_grouped['transfer'] = bag_grouped.get('Transfer', pd.Series(0, index=bag_grouped.index))\n",
    "bag_grouped['checked'] = bag_grouped.get('Checked', pd.Series(0, index=bag_grouped.index))\n",
    "bag_grouped['bag_ratio'] = bag_grouped['transfer'] / bag_grouped['checked'].replace(0, np.nan)\n",
    "bag_grouped = bag_grouped.reset_index()[['company_id', 'flight_number', 'scheduled_departure_date_local', 'bag_ratio']]\n",
    "\n",
    "# Passenger load\n",
    "pnr_grouped = pnr_df.groupby(['company_id', 'flight_number', 'scheduled_departure_date_local'])['total_pax'].sum().reset_index(name='total_passengers')\n",
    "\n",
    "# SSR\n",
    "remark_with_dates = remark_df.merge(\n",
    "    flight_df[['company_id', 'flight_number', 'scheduled_departure_date_local']],\n",
    "    on='flight_number',\n",
    "    how='left'\n",
    ")\n",
    "remark_grouped = remark_with_dates[remark_with_dates['special_service_request'] != 'None'].groupby(['flight_number', 'scheduled_departure_date_local']).size().reset_index(name='ssr_count')\n",
    "\n",
    "# Merge all dataframes\n",
    "full_df = flight_df.merge(pnr_grouped, on=['company_id', 'flight_number', 'scheduled_departure_date_local'], how='left')\n",
    "full_df = full_df.merge(bag_grouped, on=['company_id', 'flight_number', 'scheduled_departure_date_local'], how='left')\n",
    "full_df = full_df.merge(remark_grouped, on=['flight_number', 'scheduled_departure_date_local'], how='left')\n",
    "\n",
    "# Fill missing values\n",
    "full_df['total_passengers'] = full_df['total_passengers'].fillna(0)\n",
    "full_df['bag_ratio'] = full_df['bag_ratio'].fillna(0)\n",
    "full_df['ssr_count'] = full_df['ssr_count'].fillna(0)\n",
    "\n",
    "# Calculate metrics\n",
    "full_df['load_factor'] = full_df['total_passengers'] / full_df['total_seats']\n",
    "full_df['ssr_per_pax'] = full_df['ssr_count'] / full_df['total_passengers'].replace(0, np.nan).fillna(0)\n",
    "\n",
    "# Departure hour weight\n",
    "full_df['dep_hour'] = full_df['scheduled_departure_datetime_local'].dt.hour\n",
    "full_df['dep_weight'] = ((full_df['dep_hour'].between(6, 9) | full_df['dep_hour'].between(17, 20)).astype(int)) * 1.5\n",
    "\n",
    "# Haul hours\n",
    "full_df['haul_hours'] = (full_df['scheduled_arrival_datetime_local'] - full_df['scheduled_departure_datetime_local']).dt.total_seconds() / 3600\n",
    "\n",
    "# Fleet type dummies\n",
    "fleet_dummies = pd.get_dummies(full_df['fleet_type'], prefix='fleet')\n",
    "full_df = pd.concat([full_df, fleet_dummies], axis=1)\n",
    "\n",
    "# Calculate delay minutes\n",
    "full_df['delay_minutes'] = ((full_df['actual_departure_datetime_local'] - full_df['scheduled_departure_datetime_local']).dt.total_seconds() / 60).fillna(0)\n",
    "\n",
    "# Build OLS Model - dynamically get fleet columns\n",
    "fleet_cols = [col for col in full_df.columns if col.startswith('fleet_') and col != 'fleet_type']\n",
    "feature_cols = ['ground_tight', 'bag_ratio', 'load_factor', 'ssr_per_pax', 'dep_weight', 'haul_hours'] + fleet_cols\n",
    "\n",
    "# Check data types before modeling\n",
    "print(\"Data types of features:\")\n",
    "print(full_df[feature_cols].dtypes)\n",
    "print(\"\\nAny non-numeric values:\")\n",
    "print(full_df[feature_cols].select_dtypes(include=['object']).columns.tolist())\n",
    "\n",
    "# Convert all features to numeric, forcing errors to NaN\n",
    "X = full_df[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "X = sm.add_constant(X)\n",
    "y = full_df['delay_minutes']\n",
    "\n",
    "# Remove any rows where y is NaN or inf\n",
    "valid_idx = np.isfinite(y)\n",
    "X = X[valid_idx]\n",
    "y = y[valid_idx]\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "full_df.loc[valid_idx, 'difficulty_score'] = np.abs(model.predict(X))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cfdac08-6502-4c1b-855e-a5b580aa0575",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: difficulty_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m full_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(full_df[\u001b[33m'\u001b[39m\u001b[33mscheduled_departure_date_local\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m full_df[\u001b[33m'\u001b[39m\u001b[33mrank\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mfull_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdifficulty_score\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.rank(ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      3\u001b[39m full_df[\u001b[33m'\u001b[39m\u001b[33mpercentile\u001b[39m\u001b[33m'\u001b[39m] = full_df.groupby(\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mdifficulty_score\u001b[39m\u001b[33m'\u001b[39m].rank(pct=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m full_df[\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m] = pd.cut(full_df[\u001b[33m'\u001b[39m\u001b[33mpercentile\u001b[39m\u001b[33m'\u001b[39m], bins=[\u001b[32m0\u001b[39m, \u001b[32m0.33\u001b[39m, \u001b[32m0.67\u001b[39m, \u001b[32m1\u001b[39m], labels=[\u001b[33m'\u001b[39m\u001b[33mDifficult\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMedium\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEasy\u001b[39m\u001b[33m'\u001b[39m], include_lowest=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/pandas/core/groupby/generic.py:1951\u001b[39m, in \u001b[36mDataFrameGroupBy.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) > \u001b[32m1\u001b[39m:\n\u001b[32m   1945\u001b[39m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[32m   1946\u001b[39m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[32m   1947\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1948\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1949\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse a list instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1950\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/pandas/core/base.py:245\u001b[39m, in \u001b[36mSelectionMixin.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    246\u001b[39m     ndim = \u001b[38;5;28mself\u001b[39m.obj[key].ndim\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gotitem(key, ndim=ndim)\n",
      "\u001b[31mKeyError\u001b[39m: 'Column not found: difficulty_score'"
     ]
    }
   ],
   "source": [
    "full_df['date'] = pd.to_datetime(full_df['scheduled_departure_date_local'])\n",
    "full_df['rank'] = full_df.groupby('date')['difficulty_score'].rank(ascending=False)\n",
    "full_df['percentile'] = full_df.groupby('date')['difficulty_score'].rank(pct=True)\n",
    "full_df['category'] = pd.cut(full_df['percentile'], bins=[0, 0.33, 0.67, 1], labels=['Difficult', 'Medium', 'Easy'], include_lowest=True)\n",
    "output_df = full_df[['date', 'flight_number', 'scheduled_arrival_station_code', 'ground_tight', 'bag_ratio', 'load_factor', 'ssr_per_pax', 'dep_weight', 'haul_hours', 'fleet_type', 'difficulty_score', 'rank', 'category']]\n",
    "output_df.to_csv('test_johndoe.csv', index=False)\n",
    "logger.info(\"Difficulty scores saved to test_johndoe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "394436a0-9eea-48b7-ba27-73896f9dee27",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `difficulty_score` for `y`. An entry with this name does not appear in `data`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m sample_day = full_df[full_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] == full_df[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m]].head(\u001b[32m10\u001b[39m)\n\u001b[32m      2\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43msns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbarplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mflight_number\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdifficulty_score\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_day\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mTop 10 Flights by Difficulty Score - Sample Day\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m plt.xticks(rotation=\u001b[32m45\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/seaborn/categorical.py:2341\u001b[39m, in \u001b[36mbarplot\u001b[39m\u001b[34m(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, seed, units, weights, orient, color, palette, saturation, fill, hue_norm, width, dodge, gap, log_scale, native_scale, formatter, legend, capsize, err_kws, ci, errcolor, errwidth, ax, **kwargs)\u001b[39m\n\u001b[32m   2338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlen\u001b[39m:\n\u001b[32m   2339\u001b[39m     estimator = \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2341\u001b[39m p = \u001b[43m_CategoricalAggPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m=\u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2344\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2345\u001b[39m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2347\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlegend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2348\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2351\u001b[39m     ax = plt.gca()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/seaborn/categorical.py:67\u001b[39m, in \u001b[36m_CategoricalPlotter.__init__\u001b[39m\u001b[34m(self, data, variables, order, orient, require_numeric, color, legend)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     58\u001b[39m     data=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     legend=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     65\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# This method takes care of some bookkeeping that is necessary because the\u001b[39;00m\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# original categorical plots (prior to the 2021 refactor) had some rules that\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# don't fit exactly into VectorPlotter logic. It may be wise to have a second\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# default VectorPlotter rules. If we do decide to make orient part of the\u001b[39;00m\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# _base variable assignment, we'll want to figure out how to express that.\u001b[39;00m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.input_format == \u001b[33m\"\u001b[39m\u001b[33mwide\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mh\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/seaborn/_base.py:634\u001b[39m, in \u001b[36mVectorPlotter.__init__\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[32m    630\u001b[39m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28mself\u001b[39m._var_ordered = {\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[32m    637\u001b[39m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[32m    638\u001b[39m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mhue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstyle\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/seaborn/_base.py:679\u001b[39m, in \u001b[36mVectorPlotter.assign_variables\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    675\u001b[39m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[32m    676\u001b[39m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[32m    677\u001b[39m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mself\u001b[39m.input_format = \u001b[33m\"\u001b[39m\u001b[33mlong\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     plot_data = \u001b[43mPlotData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    680\u001b[39m     frame = plot_data.frame\n\u001b[32m    681\u001b[39m     names = plot_data.names\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/seaborn/_core/data.py:58\u001b[39m, in \u001b[36mPlotData.__init__\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     53\u001b[39m     data: DataSource,\n\u001b[32m     54\u001b[39m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[32m     55\u001b[39m ):\n\u001b[32m     57\u001b[39m     data = handle_data_source(data)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     frame, names, ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_assign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.frame = frame\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.names = names\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jupyter/env/lib/python3.13/site-packages/seaborn/_core/data.py:232\u001b[39m, in \u001b[36mPlotData._assign_variables\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    231\u001b[39m         err += \u001b[33m\"\u001b[39m\u001b[33mAn entry with this name does not appear in `data`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    235\u001b[39m \n\u001b[32m    236\u001b[39m     \u001b[38;5;66;03m# Otherwise, assume the value somehow represents data\u001b[39;00m\n\u001b[32m    237\u001b[39m \n\u001b[32m    238\u001b[39m     \u001b[38;5;66;03m# Ignore empty data structures\u001b[39;00m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(val) == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: Could not interpret value `difficulty_score` for `y`. An entry with this name does not appear in `data`."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_day = full_df[full_df['date'] == full_df['date'].iloc[0]].head(10)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='flight_number', y='difficulty_score', hue='category', data=sample_day)\n",
    "plt.title('Top 10 Flights by Difficulty Score - Sample Day')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Difficulty Score')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
